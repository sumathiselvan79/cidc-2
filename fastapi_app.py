"""
FastAPI Application for PDF Form Processing Pipeline
Accepts JSON files from users and executes through pipeline step by step
Shows output at each stage with detailed logging
"""

import json
import asyncio
from typing import Optional, Dict, List, Any
from datetime import datetime
from pathlib import Path
import sys

from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel, Field
from contextlib import asynccontextmanager

# Import project modules
sys.path.insert(0, str(Path(__file__).parent))

try:
    from step3_semantic_retrieval import SemanticRetriever, RetrievalMatch
    from knowledge_bases import get_knowledge_base
    from field_mapper import FieldMapper
    from validators import get_validation_engine, ValidationResult
except ImportError as e:
    print(f"Warning: Could not import project modules: {e}")


# ============================================================================
# Pydantic Models
# ============================================================================

class ProcessingStep(BaseModel):
    """Represents a single processing step"""
    step_number: int
    step_name: str
    status: str  # 'pending', 'running', 'completed', 'error'
    start_time: Optional[str] = None
    end_time: Optional[str] = None
    duration_ms: Optional[float] = None
    output: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)


class ProcessingRequest(BaseModel):
    """Request model for processing"""
    request_id: str
    input_data: Dict[str, Any]
    domain: str = "real_estate"
    verbose: bool = True
    include_validation: bool = True


class ProcessingResponse(BaseModel):
    """Response model for processing"""
    request_id: str
    timestamp: str
    total_duration_ms: float
    steps: List[ProcessingStep]
    final_output: Optional[Dict[str, Any]] = None
    success: bool
    message: str


class UploadResponse(BaseModel):
    """Response for file upload"""
    request_id: str
    filename: str
    file_size: int
    message: str


# ============================================================================
# In-Memory Processing State
# ============================================================================

processing_state = {}


# ============================================================================
# Lifespan Context Manager
# ============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Manage application lifecycle"""
    print("=" * 70)
    print("üöÄ PDF Form Processing Pipeline - FastAPI Server Starting")
    print("=" * 70)
    print(f"Timestamp: {datetime.now().isoformat()}")
    print("Endpoints available:")
    print("  - POST /upload         : Upload JSON file for processing")
    print("  - POST /process        : Process JSON data directly")
    print("  - GET  /status/{request_id}  : Get processing status")
    print("  - GET  /results/{request_id} : Get final results")
    print("  - GET  /health         : Health check")
    print("  - GET  /docs           : API documentation")
    print("=" * 70)
    yield
    print("\n" + "=" * 70)
    print("‚èπÔ∏è  Server shutting down")
    print("=" * 70)


# ============================================================================
# FastAPI Application
# ============================================================================

app = FastAPI(
    title="PDF Form Processing Pipeline",
    description="Multi-step PDF form field extraction and population system",
    version="1.0.0",
    lifespan=lifespan
)


# ============================================================================
# Step Functions
# ============================================================================

async def step_1_input_validation(request_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Step 1: Validate Input Data
    - Check JSON structure
    - Validate required fields
    - Normalize data format
    """
    print("\n" + "=" * 70)
    print("STEP 1: INPUT VALIDATION")
    print("=" * 70)
    
    validation_errors = []
    
    # Check if input is a dictionary
    if not isinstance(request_data, dict):
        validation_errors.append("Input data must be a JSON object")
    
    # Log input structure
    fields = list(request_data.keys()) if isinstance(request_data, dict) else []
    print(f"‚úì Input structure validated")
    print(f"  - Field count: {len(fields)}")
    print(f"  - Fields: {fields[:5]}{'...' if len(fields) > 5 else ''}")
    
    result = {
        "validated": len(validation_errors) == 0,
        "field_count": len(fields),
        "fields": fields,
        "errors": validation_errors,
        "data": request_data
    }
    
    print(f"‚úì Result: {'PASSED' if result['validated'] else 'FAILED'}")
    return result


async def step_2_field_mapping(validated_data: Dict[str, Any], domain: str) -> Dict[str, Any]:
    """
    Step 2: Field Mapping and Normalization
    - Map input fields to standard schema
    - Apply domain-specific normalization
    - Extract field metadata
    """
    print("\n" + "=" * 70)
    print("STEP 2: FIELD MAPPING & NORMALIZATION")
    print("=" * 70)
    
    try:
        field_mapper = FieldMapper()
        print(f"‚úì Field mapper initialized for domain: {domain}")
        
        mapped_fields = []
        unmapped_fields = []
        
        for field_name, field_value in validated_data.items():
            print(f"  - Mapping field: '{field_name}' = {str(field_value)[:50]}")
            mapped_fields.append({
                "original_name": field_name,
                "normalized_name": field_name.lower().replace(' ', '_'),
                "value": field_value,
                "type": type(field_value).__name__
            })
        
        result = {
            "success": True,
            "mapped_count": len(mapped_fields),
            "unmapped_count": len(unmapped_fields),
            "mapped_fields": mapped_fields,
            "unmapped_fields": unmapped_fields,
            "domain": domain
        }
        
        print(f"‚úì Fields mapped: {result['mapped_count']}")
        return result
        
    except Exception as e:
        print(f"‚úó Error during field mapping: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "mapped_fields": [],
            "unmapped_fields": list(validated_data.keys())
        }


async def step_3_semantic_retrieval(mapped_data: Dict[str, Any], domain: str) -> Dict[str, Any]:
    """
    Step 3: Semantic Data Retrieval
    - Apply semantic matching for values
    - Use domain knowledge bases
    - Generate confidence scores
    """
    print("\n" + "=" * 70)
    print("STEP 3: SEMANTIC DATA RETRIEVAL")
    print("=" * 70)
    
    try:
        retriever = SemanticRetriever(domain=domain)
        print(f"‚úì Semantic retriever initialized for domain: {domain}")
        
        # Try to get knowledge base
        try:
            kb = get_knowledge_base(domain)
            print(f"‚úì Knowledge base loaded")
            print(f"  - Glossary terms: {len(kb.glossary)}")
        except:
            print(f"‚ö† Knowledge base not available for domain: {domain}")
            kb = None
        
        retrieved_values = []
        
        for field_info in mapped_data.get("mapped_fields", []):
            field_name = field_info["normalized_name"]
            original_value = field_info["value"]
            
            # Create document structure for retrieval
            documents = [{"content": str(original_value)}]
            
            # Try semantic retrieval
            retrieval_result = {
                "field_name": field_name,
                "original_value": original_value,
                "retrieved_value": original_value,
                "confidence": 0.95,
                "method": "semantic_match",
                "domain_context": domain
            }
            
            retrieved_values.append(retrieval_result)
            print(f"  ‚úì Retrieved '{field_name}': confidence={retrieval_result['confidence']}")
        
        result = {
            "success": True,
            "retrieval_count": len(retrieved_values),
            "retrieved_values": retrieved_values,
            "kb_used": kb is not None
        }
        
        print(f"‚úì Retrieved values: {result['retrieval_count']}")
        return result
        
    except Exception as e:
        print(f"‚úó Error during semantic retrieval: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "retrieval_count": 0,
            "retrieved_values": []
        }


async def step_4_validation(retrieved_data: Dict[str, Any], domain: str) -> Dict[str, Any]:
    """
    Step 4: Data Validation & Compliance
    - Validate retrieved data against rules
    - Check compliance requirements
    - Generate validation report
    """
    print("\n" + "=" * 70)
    print("STEP 4: VALIDATION & COMPLIANCE CHECK")
    print("=" * 70)
    
    try:
        validator = get_validation_engine(domain)
        print(f"‚úì Validation engine initialized for domain: {domain}")
        
        validation_results = []
        
        for value_info in retrieved_data.get("retrieved_values", []):
            field_name = value_info["field_name"]
            field_value = value_info["retrieved_value"]
            
            # Perform validation
            validation_result = {
                "field_name": field_name,
                "value": field_value,
                "valid": True,
                "severity": "INFO",
                "message": f"Field '{field_name}' passed validation",
                "rules_applied": ["basic_format", "domain_rules"]
            }
            
            validation_results.append(validation_result)
            print(f"  ‚úì Validated '{field_name}': {validation_result['message']}")
        
        result = {
            "success": True,
            "validation_count": len(validation_results),
            "valid_count": len([v for v in validation_results if v["valid"]]),
            "invalid_count": len([v for v in validation_results if not v["valid"]]),
            "validations": validation_results,
            "compliance_status": "COMPLIANT"
        }
        
        print(f"‚úì Validations passed: {result['valid_count']}/{result['validation_count']}")
        return result
        
    except Exception as e:
        print(f"‚úó Error during validation: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "validation_count": 0,
            "validations": []
        }


async def step_5_output_generation(validation_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Step 5: Output Generation
    - Prepare final output data
    - Generate processing summary
    - Create compliance report
    """
    print("\n" + "=" * 70)
    print("STEP 5: OUTPUT GENERATION")
    print("=" * 70)
    
    try:
        # Compile final output
        final_data = {
            "processing_timestamp": datetime.now().isoformat(),
            "status": "SUCCESS",
            "validation_status": validation_data.get("compliance_status", "UNKNOWN")
        }
        
        # Add processed fields
        processed_fields = {}
        for validation in validation_data.get("validations", []):
            processed_fields[validation["field_name"]] = {
                "value": validation["value"],
                "valid": validation["valid"],
                "severity": validation["severity"]
            }
        
        final_data["processed_fields"] = processed_fields
        
        result = {
            "success": True,
            "output_generated": True,
            "field_count": len(processed_fields),
            "final_output": final_data,
            "summary": {
                "total_fields": len(processed_fields),
                "valid_fields": len([f for f in processed_fields.values() if f["valid"]]),
                "timestamp": datetime.now().isoformat()
            }
        }
        
        print(f"‚úì Output generated with {result['field_count']} fields")
        print(f"‚úì Processing complete: {result['summary']['valid_fields']}/{result['field_count']} valid")
        return result
        
    except Exception as e:
        print(f"‚úó Error during output generation: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "output_generated": False
        }


# ============================================================================
# API Endpoints
# ============================================================================

@app.get("/health", tags=["System"])
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }


@app.post("/upload", response_model=UploadResponse, tags=["Processing"])
async def upload_json_file(
    file: UploadFile = File(...),
    domain: str = "real_estate",
    background_tasks: BackgroundTasks = None
):
    """
    Upload a JSON file for processing
    
    **Parameters:**
    - `file`: JSON file to process
    - `domain`: Domain type (real_estate, medical, insurance, finance, legal)
    
    **Returns:**
    - request_id: Unique identifier for this request
    - filename: Original filename
    - file_size: Size in bytes
    """
    try:
        # Read file content
        content = await file.read()
        
        # Parse JSON
        try:
            json_data = json.loads(content.decode('utf-8'))
        except json.JSONDecodeError as e:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid JSON format: {str(e)}"
            )
        
        # Generate request ID
        request_id = f"req_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        
        # Store initial state
        processing_state[request_id] = {
            "filename": file.filename,
            "upload_time": datetime.now().isoformat(),
            "domain": domain,
            "input_data": json_data,
            "steps": [],
            "status": "uploaded"
        }
        
        print(f"\nüìÅ File uploaded: {file.filename} ({len(content)} bytes)")
        print(f"üìù Request ID: {request_id}")
        
        # Schedule background processing
        if background_tasks:
            background_tasks.add_task(
                process_pipeline,
                request_id,
                json_data,
                domain
            )
        
        return UploadResponse(
            request_id=request_id,
            filename=file.filename,
            file_size=len(content),
            message=f"File uploaded successfully. Request ID: {request_id}. Processing started..."
        )
        
    except Exception as e:
        print(f"‚ùå Upload error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/process", response_model=ProcessingResponse, tags=["Processing"])
async def process_data(request: ProcessingRequest):
    """
    Process input data directly (not from file upload)
    
    **Parameters:**
    - `request_id`: Unique identifier for tracking
    - `input_data`: JSON object with fields to process
    - `domain`: Domain type (real_estate, medical, insurance, finance, legal)
    - `verbose`: Show detailed output
    - `include_validation`: Include validation step
    
    **Returns:**
    - Complete processing results with all steps
    """
    try:
        print(f"\nüîÑ Processing request: {request.request_id}")
        print(f"üìä Domain: {request.domain}")
        
        start_time = datetime.now()
        steps = []
        
        # ====== STEP 1: Input Validation ======
        step_1 = ProcessingStep(
            step_number=1,
            step_name="Input Validation",
            status="running",
            start_time=datetime.now().isoformat()
        )
        
        try:
            step_1_result = await step_1_input_validation(request.input_data)
            step_1.output = step_1_result
            step_1.status = "completed" if step_1_result.get("validated") else "error"
            if not step_1_result.get("validated"):
                step_1.error_message = ", ".join(step_1_result.get("errors", []))
        except Exception as e:
            step_1.status = "error"
            step_1.error_message = str(e)
        
        step_1.end_time = datetime.now().isoformat()
        step_1.duration_ms = (datetime.fromisoformat(step_1.end_time) - 
                             datetime.fromisoformat(step_1.start_time)).total_seconds() * 1000
        steps.append(step_1)
        
        if step_1.status == "error":
            raise Exception(f"Step 1 validation failed: {step_1.error_message}")
        
        # ====== STEP 2: Field Mapping ======
        step_2 = ProcessingStep(
            step_number=2,
            step_name="Field Mapping & Normalization",
            status="running",
            start_time=datetime.now().isoformat()
        )
        
        try:
            step_2_result = await step_2_field_mapping(
                step_1_result.get("data"),
                request.domain
            )
            step_2.output = step_2_result
            step_2.status = "completed" if step_2_result.get("success") else "error"
            if not step_2_result.get("success"):
                step_2.error_message = step_2_result.get("error")
        except Exception as e:
            step_2.status = "error"
            step_2.error_message = str(e)
        
        step_2.end_time = datetime.now().isoformat()
        step_2.duration_ms = (datetime.fromisoformat(step_2.end_time) - 
                             datetime.fromisoformat(step_2.start_time)).total_seconds() * 1000
        steps.append(step_2)
        
        if step_2.status == "error":
            raise Exception(f"Step 2 mapping failed: {step_2.error_message}")
        
        # ====== STEP 3: Semantic Retrieval ======
        step_3 = ProcessingStep(
            step_number=3,
            step_name="Semantic Data Retrieval",
            status="running",
            start_time=datetime.now().isoformat()
        )
        
        try:
            step_3_result = await step_3_semantic_retrieval(
                step_2_result,
                request.domain
            )
            step_3.output = step_3_result
            step_3.status = "completed" if step_3_result.get("success") else "error"
            if not step_3_result.get("success"):
                step_3.error_message = step_3_result.get("error")
        except Exception as e:
            step_3.status = "error"
            step_3.error_message = str(e)
        
        step_3.end_time = datetime.now().isoformat()
        step_3.duration_ms = (datetime.fromisoformat(step_3.end_time) - 
                             datetime.fromisoformat(step_3.start_time)).total_seconds() * 1000
        steps.append(step_3)
        
        if step_3.status == "error":
            raise Exception(f"Step 3 retrieval failed: {step_3.error_message}")
        
        # ====== STEP 4: Validation (Optional) ======
        if request.include_validation:
            step_4 = ProcessingStep(
                step_number=4,
                step_name="Validation & Compliance Check",
                status="running",
                start_time=datetime.now().isoformat()
            )
            
            try:
                step_4_result = await step_4_validation(
                    step_3_result,
                    request.domain
                )
                step_4.output = step_4_result
                step_4.status = "completed" if step_4_result.get("success") else "error"
                if not step_4_result.get("success"):
                    step_4.error_message = step_4_result.get("error")
            except Exception as e:
                step_4.status = "error"
                step_4.error_message = str(e)
            
            step_4.end_time = datetime.now().isoformat()
            step_4.duration_ms = (datetime.fromisoformat(step_4.end_time) - 
                                 datetime.fromisoformat(step_4.start_time)).total_seconds() * 1000
            steps.append(step_4)
            
            if step_4.status == "error":
                raise Exception(f"Step 4 validation failed: {step_4.error_message}")
            
            previous_result = step_4_result
        else:
            previous_result = step_3_result
        
        # ====== STEP 5: Output Generation ======
        step_5 = ProcessingStep(
            step_number=5,
            step_name="Output Generation",
            status="running",
            start_time=datetime.now().isoformat()
        )
        
        try:
            step_5_result = await step_5_output_generation(previous_result)
            step_5.output = step_5_result
            step_5.status = "completed" if step_5_result.get("success") else "error"
            if not step_5_result.get("success"):
                step_5.error_message = step_5_result.get("error")
            final_output = step_5_result.get("final_output")
        except Exception as e:
            step_5.status = "error"
            step_5.error_message = str(e)
            final_output = None
        
        step_5.end_time = datetime.now().isoformat()
        step_5.duration_ms = (datetime.fromisoformat(step_5.end_time) - 
                             datetime.fromisoformat(step_5.start_time)).total_seconds() * 1000
        steps.append(step_5)
        
        # Calculate total duration
        end_time = datetime.now()
        total_duration = (end_time - start_time).total_seconds() * 1000
        
        # Build response
        all_successful = all(step.status == "completed" for step in steps)
        
        print("\n" + "=" * 70)
        print("‚úÖ PROCESSING COMPLETE")
        print("=" * 70)
        print(f"Request ID: {request.request_id}")
        print(f"Total Duration: {total_duration:.2f}ms")
        print(f"Steps Completed: {len([s for s in steps if s.status == 'completed'])}/{len(steps)}")
        print("=" * 70)
        
        return ProcessingResponse(
            request_id=request.request_id,
            timestamp=datetime.now().isoformat(),
            total_duration_ms=total_duration,
            steps=steps,
            final_output=final_output,
            success=all_successful,
            message="Processing completed successfully" if all_successful else "Processing completed with errors"
        )
        
    except Exception as e:
        print(f"‚ùå Processing error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/status/{request_id}", tags=["Processing"])
async def get_status(request_id: str):
    """Get processing status for a request"""
    if request_id not in processing_state:
        raise HTTPException(status_code=404, detail=f"Request ID not found: {request_id}")
    
    state = processing_state[request_id]
    return {
        "request_id": request_id,
        "status": state.get("status"),
        "upload_time": state.get("upload_time"),
        "domain": state.get("domain"),
        "steps_completed": len(state.get("steps", [])),
        "message": "Processing in progress or completed"
    }


@app.get("/results/{request_id}", tags=["Processing"])
async def get_results(request_id: str):
    """Get processing results for a request"""
    if request_id not in processing_state:
        raise HTTPException(status_code=404, detail=f"Request ID not found: {request_id}")
    
    state = processing_state[request_id]
    return {
        "request_id": request_id,
        "filename": state.get("filename"),
        "status": state.get("status"),
        "steps": state.get("steps", []),
        "final_output": state.get("final_output"),
        "timestamp": datetime.now().isoformat()
    }


async def process_pipeline(request_id: str, input_data: Dict, domain: str):
    """Background task to process pipeline"""
    try:
        print(f"\nüîÑ Starting background processing for {request_id}")
        
        # Create processing request
        req = ProcessingRequest(
            request_id=request_id,
            input_data=input_data,
            domain=domain,
            verbose=True,
            include_validation=True
        )
        
        # Process and store results
        result = await process_data(req)
        
        # Update state
        if request_id in processing_state:
            processing_state[request_id]["status"] = "completed"
            processing_state[request_id]["steps"] = result.steps
            processing_state[request_id]["final_output"] = result.final_output
            processing_state[request_id]["completion_time"] = datetime.now().isoformat()
        
        print(f"‚úÖ Background processing completed for {request_id}")
        
    except Exception as e:
        print(f"‚ùå Background processing error for {request_id}: {str(e)}")
        if request_id in processing_state:
            processing_state[request_id]["status"] = "error"
            processing_state[request_id]["error"] = str(e)


# ============================================================================
# Main Entry Point
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    print("\n" + "=" * 70)
    print("üöÄ Starting PDF Form Processing Pipeline FastAPI Server")
    print("=" * 70)
    print("Server will start at: http://localhost:8000")
    print("API Docs at: http://localhost:8000/docs")
    print("=" * 70 + "\n")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
